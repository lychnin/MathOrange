[作者小站](https://www.adit.io/index.html)
使用二分查找时，最多需要检查$log_2n$个元素，此时列表必须有序

运行时间：
线性时间:将所有的可能性都进行呈现
对数时间:二分查找的时间，或者说所有可能的操作取对数后操作数量需要的时间

大O表示法:以操作数为单位，且表示的是最糟的情形

常用的五中大O运行时间:
O(logn)
O(n)
O(n*logn)
O($n^2$)
O(n!)

算法的速度并非指时间，而是操作数的增速

谈论算法的速度时，我们说的是随着输入的增加，其运行时间将以怎样的速度增加

数组意味着存储的元素紧挨的放在一起，如果你需要增加一个元素，那么只能重新申请一块地址，虽然可以预留位置，但这可能造成内存的浪费，并且超过数组长度后还需要进行转移
 
链表则解决了这个问题，相当于说：我们分开坐

但是如果要随机读取链表中的一个元素，那么效率就会很低，但如果随机读取数组中的元素，那么效率就会很高，直接根据索引来即可

插入元素时，链表只需修改在这个元素之前的元素存储的下个元素的地址
而数组则需将插入位置之后的元素都向后移动，而且如果数组没有足够的空间的话，需要重新分配空间

删除元素时，也是链表更为方便，只需要删除前一个元素指向的地址即可

|      | 数组 | 链表 |
| ---- | ---- | ---- |
| 读取 | O(1) | O(n) |
| 插入 | O(n) | O(1) |
| 删除 | O(n) | O(1) |

### 递归
循环有时可能性能更好，但是递归更容易理解

编写递归时，必须告诉他什么时候停止递归。所以每个递归函数都应该有两个条件:<mark>基线条件(base case)</mark>和<mark>递归条件(recusive case)</mark>。
递归条件指的是调用自己，基线条件指的是不调用自己，从而避免无限循环


### 栈
栈只有两种操作:入栈与出栈

当执行一个函数时，计算机会将函数调用涉及的所有变量的值存储到内存中，在该函数中调用另一个函数时，当前函数暂停并处于未完成状态，执行完内层函数后，回到之前的函数从离开的地方继续执行

这个栈被称为调用栈

![](../../blog_picture/stack1.png)
![](../../blog_picture/stack2.png)
![](../../blog_picture/stack3.png)
![](../../blog_picture/stack4.png)

在递归函数中，外层函数执行到return后，就进入该函数调用的里层函数，然后重复，直到进入最里层函数，最里层函数返回确定值，在逐一返回外层函数
<mark>另外，在这个过程中，里层与外层函数的相同名称变量并不相同</mark>

使用循环方法时，相当于将所有的盒子摆出来查找
![](../..\blog_picture\stack5.png)

使用递归时，则相当于将这些盒子嵌套起来，在盒子中找东西就是入栈的过程

![](../..\blog_picture\stack6.png)

![](../..\blog_picture\stack7.png)

虽然栈很方便。但是存储详尽的信息可能占用大量的内存，如果栈很高，则说明计算机存储了大量函数调用的信息:
改善方法:
重新编写代码，使用循环
使用尾递归

## 快速排序
探索<mark>分而治之(divide and conquer,D & C)</mark>-一种著名的递归式问题解决方法，分而治之就是先将问题规模减小，然后处理。

快速排序是一种D&C算法

使用D&C解决问题的过程包括两个步骤：
- 找出基线条件，这种条件必须尽可能简单
- 不断将问题分解(缩小问题规模)，直到符合基线条件

归纳证明:
归纳证明是一种证明算法行之有效的方式，它分为:基线条件与归纳条件。

归纳条件就是说从k可以推到k+1，基线条件就是说k=1时有效。

### 算法复杂度中的常量
两个大O表示法相同复杂度的算法，常量会使得它们的速度不同，例如：快速排序和合并查找但是如果大O表示法不同，那么常量的影响就可以忽略不计了。

<mark>算法所需的固定时间量，称为常量</mark>

### 平均情况与最佳情况
![](../..\blog_picture\最糟情况.png)
最糟情况是每次将第一个元素作为基准值，由于数组并没有被分为两半，会进行n次

平均情况/最佳情况
![](../..\blog_picture\平均情况.png)
但是如果每次将数组分为两半，就不需要那么多递归调用了，只需要进行$logn$次

两种方法的<mark>调用栈的高度</mark>分别为$O(n)$与$O(logn)$

每层完成的操作时间为$O(n)$<mark>注意是$O(n)$而不是n</mark>
![](../..\blog_picture\every.png)

所以，对快速排序来说，最佳情况是$O(n)*O(logn)=O(nlogn)$
最糟情况是$O(n)*O(n)=O(n^2)$

## 散列表
需要满足一些要求:
- 输入相同时，输出也需要相同
- 应该将不同的输入映射到不同的数字

散列函数使我们不用查找，一步到位，之所以能做到这样，是因为：
- 散列函数总是将同样的输入映射到相同的索引

- 散列函数将不同的输入映射到不同的索引

- 散列函数只返回有效索引

数组与链表都被直接映射到内存，但是散列表更复杂，它使用散列函数来确定元素的存储位置,包含了额外的逻辑

散列表又称为散列映射、映射、字典和关联数组。

任意优秀的语言都提供了散列表实现，在python中，这就是字典dict

### 将散列表用于查找
Python中创建一个散列表:
```python
new_dict=dict()
new_dict={}
```
在访问网站时，链接都会被转换为IP地址访问，散列表可以提供这种功能，这种功能称为DNS解析(Domain Name System)域名解析

缓存的原理：网站将数据记住，而不需要再进行重新获取
![](../..\blog_picture\webcache.png)
这是一个URL与页面数据的散列表
![](../..\blog_picture\缓存.png)


小结一下：
散列表适用于
- 模拟映射关系
- 防止重复
- 缓存/记住数据，以防服务器再通过处理来生成这些数据

在散列表中，当两个输入对应同一个输出时，就意味着发生了冲突(collision)。

最简单的解决办法是:
如果两个键映射到了同一位置，那么就在这个位置存储一个链表

我们在选择散列函数时需要注意:
- 好的散列函数可以将键均匀地映射到散列表的不同位置
- 好的散列函数不会令链表变得很长

虽然散列表在平均情况下，所有的操作都是常量时间O(1)，但是在最糟情况下，其查找、插入、删除时间都是O(n)

因此，避开最糟情况很重要，为此，需要避开冲突
- 较低的填装因子
- 良好的散列函数

填装因子:
$\frac{散列表中的元素数}{位置总数}$
当填装因子大于0.7意味着商品数量超过了数组的位置数，需要在散列表中添加位置，称为调整长度(resizing)

填装因子越小，发生冲突的可能性越小

散列函数:
良好的散列函数可以让数组中的值均匀分布

广度优先搜索(breadth-first search,BFS)

最短路径问题(shortest-path problem)，解决最短路径问题的算法被称为广度优先搜索。

图是什么
图由节点与边组成

两节点间若有一条边相连，则两节点互为邻居。

广度优先搜索先搜索一度关系，再搜索二度关系

### 队列
队列只支持两种操作:入队与出队
队列是一种先进先出的数据结构，而栈是一种后进先出的数据结构。

python中创建一个双端队列
```python
from collection import deque 
search_queue=deque()
```

键值对的添加顺序没有影响，因为散列表无序

有向图(directed graph)带有箭头
无向图(undirected graph)不带有箭头

检查完一个人后就应该将它标记，否则可能会陷入无限循环，而且会多做很多无用功

广度优先搜索的运行时间:
因为要将每个人加入到队列中，所以为O(人数),又因为要检查每个人，沿着图的边进行，所以为O(边数),总时间为O(顶点数+边数)

## 迪杰斯特拉算法(Dijkstra's Algorithm)
在使用广度优先搜索时，找到的是从起点开始，经过边数最少的路径，但是当每条边被分配了权重后，再使用广度优先搜索时就不好用了。

而迪杰斯特拉算法可以找到总权重最小的路径。

步骤:
- 1.找到最近的节点
- 2.对于该最近结点的邻居，检查与当前前往它们的距离相比是否有更近的距离，如果有就更新
- 3.重复这个过程，直到遍历完整个图
- 4.计算最终路径

迪杰斯特拉算法其实就是一种每次都选最优解的算法，贪心
### 术语
权重:图中的每条边都有关联数字，这些数字就是权重

加权图:带权重的图就称为加权图

非加权图:不带权重的图

计算非加权图中的最短路径，可以使用广度优先搜索

计算加权图中的最短路径，可以使用迪杰斯特拉算法

环:从一个点出发，如果有一条路径能够走回这个点，那么这就是一个环

其实无向图就意味着有环

迪杰斯特拉算法只适用于有向无环图(directed acyclic graph,DAG)

### 负权边
当两个结点之间的权值为负数时，就不能使用迪杰斯特拉算法了，因为权值为负时，会导致:
一个已经被标记了最短路径的结点，在另一条路径中出现了更短的到达这个结点的路径，但是这条更短的路径已经无法更新了。

要解决带负权边的图的最短路径问题，可以使用贝尔曼-福德算法(Bellman-Ford Algorithm)

### 实现
python中创建一个无穷大的数的表示：
```python
infinity=float("inf")
```

## 贪婪算法
贪婪算法的优点:
简单易行，即每步都选择局部最优解，最终得到的就是全局最优解

<mark>当然，贪婪算法并非在任何情况下都有效</mark>

在很多情况下，完美是优秀的敌人，有时候，只需要找到一个能够大致解决问题的算法，此时贪婪算法恰好可以派上用场。

贪婪算法虽然并不一定能得到最优解，但是可以得到近似解，评价近似解优劣的标准:
- 速度有多快
- 得到的近似解与最优解的接近程度


### NP完全问题
如果能够识别一个问题时NP完全问题，那么我们现在还没有找到最佳的解决方法,最佳的做法是使用近似算法。<mark>但是现在没办法判断问题是不是NP完全问题</mark>。

以下是一些经验:
- 元素较少时算法的运行速度非常快，但随着元素数量的增加，速度会变得非常慢。
- 涉及“所有组合”的问题通常是NP完全问题。
- 不能将问题分成小问题，必须考虑各种可能的情况。这可能是NP完全问题。
- 如果问题涉及序列（如旅行商问题中的城市序列）且难以解决，它可能就是NP完全问题。
- 如果问题涉及集合（如广播台集合）且难以解决，它可能就是NP完全问题。
- 如果问题可转换为集合覆盖问题或旅行商问题，那它肯定是NP完全问题。













