西瓜书建议使用方式：
1.学习机器学习的第一本书
读三次
第一次通读速度，细节不懂就略过，第一次要快，一个月内读完
了解机器学习的疆域、基本思想、基本概念

2.阅读其他具体分支的读物（三月、半年）
最可怕的是你不知道它的存在

3.再读，对关键点理解：
理解技术细冗后的本质，升华认识

4.对机器学习多个分支有所了解（1-3年）

5.再读、再思
有些联系以前没有注意到，启发可能自行摸索数年不易得

## 绪论
机器学习是什么？
科学、技术、应用、工程有什么区别：
科学解决是什么与为什么

技术解决怎么做

工程解决怎么样做的多快好省

经典定义：利用经验改善系统自身的性能【T.Mitchell教科书 1997】

经验-->数据（在计算机系统中存在形式）

利用经验=分析数据

产生出了很多分析数据的技术

目前主要研究**智能数据分析（数据分析在计算机算法）**的理论与方法，

$大数据\neq大价值$ 

数据智能分析-->机器学习

label标记: 
训练数据-->训练-->模型

新数据样本-->模型-->判断类别

学习算法用以训练

研究核心：学习算法

并不是每次学习算法得到的结果相同

算法针对什么数据有效，产生的模型什么时候有效

## 术语
属性值attribute value
样本/属性/输入空间attribute/sample/input space
特征向量vector
维数dimensionality
学习/训练learning/training
training data:training sample's set-->training set
真相/真实ground-truth
学习器learner
标记label
样例/样本example/instance
假设hypothesis

测试testing
测试样本testing sample
监督学习supersized learning
无监督学习unsupersized learning
泛化能力generalization：学得模型适用于新样本的能力

独立同分布independent and identically distributed

归纳induction与演绎decution
归纳学习inductive learning
- 广义：从样例中学习
- 狭义：从训练数据中学得概念，因此亦称概念学习或者概念形成

"记住"训练样本，就 是所谓的"机械学习" [Cohen and Feigenbaum. 1983]. 或称"死记硬背式 学习"：以后对未见的样本则没有判断力

假设空间：所有可能的结果组成的空间

通过各种方式对假设空间的探索，不断删除其中与正例不一致的假设（非正例）就可得到与训练集一致的假设

版本空间/假设集合version space/hypothesis set:与训练集一致的多个假设的集合

inductive bias归纳倾向：由于某种知识作为背景，算法在遇到选择时，更倾向于某一类

任何一个有效的机器学习算法必有其归纳偏好

"奥卡姆剃刀" (Occam's razor) 是一种常用的、自然科学 研究中最基本的原则，即"若有多个假设与观察一致，则选最简单的那个，但并非唯一可行的原则

训练集外误差：

意外得到总误差与算法无关

NFL定理，没有免费午餐定理:有一个重要前提，所有的问题出现的机会均等



NFL 走理最重要的寓意是让我们清楚地认识到，脱离具体问题，空泛地谈论"什么学习算法更好"毫无意义，

1980 年夏，在美国卡耐基梅隆大学举行了第一届机器学习研讨会 (IWML); 同年， ((策略分析与信息系统》连出三期机器学习专辑; 1983 年， Tioga 山版社 出版了R. S. Michalski 、 J. G. Carbonell 和 T. Mitchell 主编的《机器学习:一 种人工智能途径)) [Michalski et al., 1983] ，对当时的机器学习研究工作进行了 总结; 1986 年 7 第→本机器学习专业期刊 Machine LeαTηing 创刊; 1989 年，人工智能领域的权威期刊 Artificial Intelligence 出版机器学习专辑，刊发了当时 一些比较活跃的研究工作?其内容后来出现在 J. G. Carbonell 主编、 MIT 出 版社 1990 年的《机器学习:范型与方法>>


1. 7 阅读材料 [Mitchell, 1997] 是第一本机器学习专门性教材， [Duda et al., 2001; Alc paydin, 2004; Flach, 2012] 都是出色的入门读物. [Hastie et al. , 2009] 是很好 的进阶读物， [Bishop, 2006] 也很有参考价值?尤其适合于贝叶斯学习偏好者. [Shalev-Shwartz and Ben-David, 2014] 则适合于理论偏好者. [Witten et 此， 2011] 是基于 WEKA 撰写的入门读物 7 有助于初学者通过 WEKA 实践快速掌 握常用机器学习算法. 本书1. 5 和1. 6 节主要取材于[周志华， 2007]. ((机器学习:一种人工智能 途径)) [Michalski et al., 1983] 汇集了 20 位学者撰写的 16 篇文章，是机器学习 早期最重要的文献.该书出版后产生了很大反响， Morgan Kaufmann 出版社后 来分别于 1986 年和 1990 年出版了该书的续篇，编为第二卷和第二卷. ((人
 17 智能手册》系列是图灵奖得主 E. A. Feigenbau日1 与不同学者合作编写而成，该 书第三卷 [Cohen and Feigenbaum, 1983] 对机器学习进行了讨论，是机器学习 早期的重要文献. [Dietterich, 199可对机器学习领域的发展进行了评述和展望. 早期的很多文献在今天仍值得重视，一些闪光的思想在相关技术进步后可能焕 发新的活力，例如近来流行的"迁移学习" (transfer learning) [Pan and Yang, 2010] ，恰似"类比学习" (1earning by analogy) 在统计学习技术大发展后的升 级版;红极一时的"深度学习" (deep learning) 在思想上井未显著超越二十世 深度学习参见 5.6 节 纪八十年代中后期神经网络学习的研究. 机器学习中关于概念学习的研究开始很早，从中产生的不少思想对整个 领域都有深远影响.例如作为主流学习技术之一的决策树学习，就起源于关 于概念形成的树结构研究 [Hu日.t and Hovlar吨 1963]. [Winston, 1970] ;在著 名的"积木世界"研究中，将概念学习与基于泛化和特化的搜索过程联系起 来. [Simon and Lea, 1974] 较早提出了"学习"是在假设空间中搜索的观点. [Mitchell, 197句稍后提出了版本空间的概念.概念学习中有很多关于规则学习 规则学习参见第 15 章 的内容. 集成学习参见第 8 章. 奥卡姆剃刀原则主张选择与经验观察一致的最简单假设 7 它在自然科学如 物理学、天文学等领域中是一个广为沿用的基础性原则，例如哥白尼坚持"日 心说"的理由之一就是它比托勒密的"地心说"更简单且符合天文观测.奥 卡姆剃刀在机器学习领域也有很多追随者 [Blumer et al., 1996]. 但机器学习 中什么是"更简单的"这个问题一直困扰着研究者们，因此，对奥卡姆剃刀在 机器学习领域的作用一直存在着争议阳"ebb ， 1996; Domingo民 1999]. 需注意 的是，奥卡姆剃刀并非科学研究中唯一可行的假设选择原则，例如古希腊哲学 家伊壁坞鲁(公元前341年一前270年)提出的"多释原则" (principle of multiple explanations) ，主张保留与经验观察一致的所有假设 [Asmis ， 1984]，这与集成 学习 (ensemble learning) 方面的研究更加吻合. 机器学习领域最重要的国际学术会议是国际机器学习会议 (ICML) 、国际 神经信息处理系统会议 (NIPS) 和国际学习理论会议 (COLT) ，重要的区域性会 议主要有欧洲机器学习会议 (ECML) 和亚洲机器学习会议 (ACML); 最重要的 国际学术期刊是 Journal of Machine Learning Research 和 Machine Learning. 人工智能领域的重要会议如 IJCAI、 AAAI 以及重要期刊如 Art侨c归1 Intelligence 、 Journal of Art听 cial Intelligence Reseαrch， 数据挖掘领域的重要会议 如 KDD 、 ICDM 以及重要期刊如 ACM Transactions on Knowledge Discovery fromDα归、 Dαtα Mining and Knowledge Discovery， 计算机视觉与模式识别领域的重要会议如 CVPR 以及重要期刊如 IEEE Transactions on Pattem Analysis and Machine Intelligence， 神经网络领域的重要期刊如 Neural Computation 、 IEEE Transaιtions on Neural Networks αη d Leαming 8ystems 等 也经常发表机器学习方面的论文.此外，统计学领域的重要期刊如 Annals 旷 8tαtistics 等也常有关于统计学习方面的理论文章发表. 国内不少书籍包含机器学习方面的内容，例如[陆汝铃， 1996]. [李航， 2012] 是以统计学习为主题的读物.国内机器学习领域最主要的活动是两年一次 的中国机器学习大会 (CCML) 以及每年举行的"机器学习及其应用"研讨 会 (MLA); 很多学术刊物都经常刊登有关机器学习的论文.


 ## 模型评估与选择

经验误差与过拟合

分类错误的样本数占样本总数的比例称为"错误率" (error rate)，则错误率 E= α/m;
1 一 α/m 称为"精度" (acc旧acy) ，即"精度 =1 一错误率"

实际预测输出与样本的真实输出之间的差异称为"误差" (error)

学习器在训练集上的误差称为"训练误差" (training error) 或"经验误 差" (empirical error)

新样本的误差为泛化误差

实际希望的，是在新样本上能表现得很好的学习器

过拟合overfitting：过拟合是无法彻底避免的，我们所能做 的只是"缓解'气或者说减小其风险

欠拟合underfitting

NP难

因此只要 相信 "$p \neq NP $" ，过拟合就 不可避免

理想的解决方案当然是对候选模型的泛化误差进行 评估 7 然后 选择泛化误差最小的那个模型.然而如上面所讨 论的，我们无法直接获得泛化 误 差，而训练误差又由于过拟 合现象的存在 而不 适 合 作为标准

 测试集上的"测试误差" (testing error) 作为 泛化误差的 近似

 测试集应该尽可能 与训练集互斥

只有一个包含 m 个样例的数据集 D={(叫 ， Yl) ,(X2 ,Y2) , ... 7 (Xm ， Ym)} ， 既要训练，又要测试，怎样才能做到呢?答案是:通过对 D 进行适当 的处理，从中产生出训练集 S 和测试集 T


- 留出法
  "留出法" (hold-out) 直接将数据集 D 划分为两个互斥的集合?其中一个 集合作为训练集 5 ，另一个作为测试集 T，

 训练/测试集的划分要尽可能保持数据分布的一致性，
 避免困数据划分过程引入额外的偏差而对最终结果产生影响
 从来样 (sampling) 的角度来看待数据 集的划分过程，则保留类别比例的采样方式通常称为"分层采样" (stratified sampling).

单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法时，一般使用若干次随机划分，重复进行实验评估后取平均值作为最终的评估结果

但是对于留出法来说，有一个天生的缺陷：若测试集的样本数量更多，那么训练集的样本数量和样本总量的差距就比较大了，会导致训练出的模型不准确会导致评估结果不准，若训练集的样本数量多，那么测试集的样本数量就会少，会导致泛化误差不准确，评估结果不准确

常见做法：将大约2/3~4/5的样本用于训练，剩余样本用于测试

### 交叉验证法
- 先将数据集D划分为k个大小相似的互斥子集，每个子集尽可能保持数据分布的一致性，即从D中通过分层采样得到，
- 然后，每次用k-1个子集的并集作为训练集，余下的子集作为测试集。
- 这样就可以获得k组训练集/测试集，进行k次训练与测试
- 最终返回的是k个测试结果的均值
  
交叉验证评估结果的稳定性与保真性很大程度上取决于k的取值，为强调这一点，通常把交叉验证法称为“k折交叉验证(k-fold cross validation)”,k最常用的数值是10

==notes：值得注意的是，k次k折交叉验证是进行了$k^2$次训练->测试==

#### 极限情况
假定数据集D中包括m个样本，若令k=m，则得到特例：留一法(leave-one-out,简称LOO)
留一法的优点：被实际评估的模型与期望评估的用D训练出的模型很相似，因此结果比较准确

也有缺陷：数据集比较大时，训练M个样本的计算开销难以承受

而且，留一法也不是真的永远比其他评估方法都准确，“没有免费的午餐”定理对其同样适用

## 自助法bootstrapping
直接以自助采样法（bootstrap sampling）为基础

给定包含m个样本的数据集D，我们对其进行采样产生数据集R：
- 每次随机从D中挑选一个样本，将其拷贝放入D'
- 然后再将该样本放回初始数据集中
- 重复执行（采样、放回）m次，得到了包含m个样本的数据集R
- 将D\R（\为集合减法）作为测试集
- 这样的测试结果称为包外估计(out-of-bag estimate)


数据集中有一部分样本会在R中重复出现，也定会有一些样本不会出现，样本在m次采样中始终不会出现的概率是$\displaystyle \lim_{m \to \infty }(1-\frac{1}{m} m)^m \to \frac{i}{e} \approx 0.368$

优点：数据集较小、难以有效划分训练集/测试集时很有用

可以产生多个不同的训练集，这对集成学习等方法有很大的好处

缺点：自助法产生的数据集改变了初始数据集的分布，会引入估计偏差，因此在数据量充足时，留出法与交叉验证法更常用


调参与最终模型
大多数学习算法都有参数需要设定，参数配置不同，学得的模型的性能往往有显著差别

对每种参数配置训练出模型是不可行的，常用做法是对每个参数选定一个范围和变化步长

==我们在使用训练集进行训练，测试集评估后，选定了学习算法与参数，此时应该用数据集D重新训练模型，在训练过程中使用了所有m个样本，这才是最终应该提交给用户的模型==

学得模型在实际使用中遇到的数据称为测试数据，模型评估与选择中用于评估测试的数据常称为"验证集”validation set
测试集与验证集的关系应该是：
```mermaid
graph LR
D-->训练数据
训练数据-->训练集
训练数据-->验证集_模型评估与选择中，用于评估测试的数据集
D-->测试数据_用于对泛化误差进行评估选择
```

### 性能度量
衡量模型泛化能力的评价标准

性能度量也反映了任务需求

### 回归任务最常用的性能度量是“均方误差”mean squared error

$E(f;D)=\frac{1}{m}\displaystyle \sum^m_{i=1}(f(x_i)-y_i)^2$

更一般地描述：
$E(f;D)=\int _{x\in D}f(x)p(x)dx $

### 错误率与精度
分类任务中最常用的两种性能度量



查准率与查全率、F1



