高性能计算值是指通常使用使用多个处理器或多个计算机组成的计算系统与环境，执行pc无法处理的大量资料与高速运算。

1946-1957 电子管计算机
1958-1964 晶体管计算机
1965-now  集成电路计算机


机柜用来存放服务器，1U意为高度，约为4.44cm，还可以用来隔音，还可以搭建制冷系统，用来散热
![](D:/VSCode\blog_picture\机柜.png)

==性能衡量-HPL==(High Performance Linpack)
测试高性能计算系统浮点运算的基准测试程序。
通过对高性能计算机采用高斯消元法，求解一元N次稠密线性代数方程组，评价高性能计算的浮点性能:$Ax=b$

==每秒浮点运算次数==(FLOPS Floating-Point Operation Per Second)
FLOPS中的s必须大写，若为小写，则意为衡量算法复杂度Floating Pointing of  
Operations


浮点运算包括所有涉及小数的运算，比整数更费时间，每秒浮点运算实际上就是浮点运算器的执行速度。

一个MFLOPS（megaFLOPS）等于每秒一百万（=$10^6$）次的浮点运算，

一个GFLOPS（gigaFLOPS）等于每秒十亿（=$10^9$）次的浮点运算，

一个TFLOPS（teraFLOPS）等于每秒一万亿（=$10^{12}$）次的浮点运算，(1太拉)

一个PFLOPS（petaFLOPS）等于每秒一千万亿（=$10^{15}$）次的浮点运算，

一个EFLOPS（exaFLOPS）等于每秒百亿亿（=$10^{18}$）次的浮点运算，

==HPCC==(High Performance Computing Challenge)面向高性能计算机的综合测试程序包，测试多个指标，包括处理器速度、存储访问速度等。==但是评价体系不够健全==

==HPCG==(High Performance Conjugate Gradients)高性能共轭梯度基准测试，Top500重要指标。

全球高性能计算机TOP500排名
德国ISC会议与美国SC会议，会进行排名发布

==计算峰值==表示每秒完成的浮点运算最大次数，==包括理论计算峰值与实测浮点峰值==

运算性能：实测浮点峰值

峰值性能：理论浮点峰值

![](D:/VSCode\blog_picture\bit.png)

# 为什么要进行并行计算
- 单处理器提升速度降低
- 串行程序运行在单处理器上，不会因为处理器数量的增加而增强性能

## 为什么需要不断提升性能
气候模拟、蛋白质折叠、药物发现、能源研究、数据分析等领域需要更强大的计算能力

## 为什么需要构建并行系统

较小的晶体管=更快的处理器=增加功耗=增加热量=导致集成电路变得太热变得不可靠

为此，集成电路商的决策是：与其构建更快更复杂的单处理器，不如在单个芯片上放置多个相对简单的处理器，这样的处理器称为==多核处理器==，核已经成为中央处理器或者CPU的代名词了，在这样的设定下，传统的只有一个CPU的处理器称为单核处理器

## 为什么要编写并行程序
大多数为传统单核系统编写的程序无法利用多核处理器。

为此，我们需要将串行程序改写为并行程序或者研究一个程序可以将串行程序自动转化为并行程序

但是在串行程序自动转化为并行程序的路上鲜有突破

一个串行程序的高效并行实现可能不是通过发掘其中的每一个步骤的高效运行来实现，==最好的并行化实现可能是通过回溯，发现一个全新的算法==

eg:求n个元素的和
```C++
my_sum=0;
my_first_i=...;
my_last_i=...;
for(my_i=my_first;my_i<my_last_i;my_i++){
    my_x=Compute.next_value(...);
    my_sum+=my_x;
}
```
my_开头的变量代表每个核的私有变量，如果此时有24个数(并非1-24)相加，我们拥有8个核，我们只需要令每个核计算三个数的和，将三个数的累加存储在核中，最后都发送到master核，在master核上进行累加。

另一个方法是:
令偶数核与其相邻的奇数核的数字在偶数核上相加，再令各个偶数核的数字进行累加。如下图

![](D:/VSCode\blog_picture\sum.png)
但是，当核比较多时，master核完成所有的累加工作会导致压力过大。

优化前后，master核==都==承担了最大的工作量，又计算了8次，优化后只计算了3次，因此优化后快了两倍，当有更多的核时，优化更明显。

优化前相当于对串行求和程序的一般化，优化后则与原来的串行算法关系不大了。

但是问题在于，自动翻译很难发现优化后的方法。所以我们不能再继续编写简单的串行程序，而应该发掘多核处理器的潜能。

## 怎样编写应用程序
两种广泛采用的方法:
- 数据并行
    指将待解决的问题所需要处理的数据分配给各个核
- 任务并行
    将待解决的问题所需要执行的任务分配给多个核上进行

在各个核独立工作时，编写并行程序其实与串行程序差不多，但当核之间需要进行通信时，就会变得复杂，但是核之间的通信是常见的。

协调过程包括：
- 通信
    一个或多个核将自己的部分发送给起他核。
- 负载平衡
    每个核分配大致相同数目的数据来计算
- 同步
    各个核之间并不会自动同步的，但是

    可以加入Synchronize_cores，令各个核在此函数处等待，直到master进入该函数

|                  |                        |                  |
| ---------------- | ---------------------- | ---------------- |
|                  | MPI                    | MapReduce        |
| 集群架构/容错性  | 分布式，容错性差       | 分布式，容错性好 |
| 硬件/价格/扩展性 | 价格贵，扩展性差       | 便宜，扩展性好   |
| 编程/学习难度    | 难                     | 简单             |
| 应用             | 超级计算机性能上的提升 | 大数据处理分析   |

目前，功能最强大的并行程序通过显式的并行结构来编写，即用扩展C++、扩展C编写，这些程序包含显式的并行指令，即便在编写单个核上运行的代码，也要特别注意。

当单个机器的性能无法提升时，可以通过建立集群来完成

## 接下来的学习
接下来，我们将学习如何编写显式的并行程序，学会利用C语言以及C语言的三种扩展，消息传递接口(Message-Passing Inferface,MPI)、POSIX线程(POSIX threads，Pthreads)
、OpenMP,前两个是C语言的 扩展库，最后一个包含一个扩展库，及对编译器的部分修改。

我们关注的两种主要并行系统是:共享内存系统与分布式内存系统。

- 共享内存系统中各个核能够共享访问计算机的内存，理论上每个核能够读、写内存的所有区域。
- Pthreads和OpenMP是为共享内存系统的编程而设计的。

OpenMP是对C语言的相对更高层次的扩展。
Pthreads提供了一些在OpenMP中不可用的协调构造，OpenMp容易将很多程序并行化。

## 并发、并行、分布式
在==并发计算==中，一个程序的多个任务在同一时段内可以同时执行
在==并行计算==中，一个程序通过多个任务紧密协作来解决某个问题
在==分布式计算==中，一个程序需要与其他程序协作来解决某个问题

并行程序与分布式程序都是并行程序

这些术语之间还没有统一的规定

并行计算与分布式计算的区别:
相似点:都是为了实现比较复杂的任务，将大的任务分解为小任务，在多台计算机上同时计算

并行计算：
- 一个程序通过多个任务紧密协作来解决某一个问题

- 目的：是使用多个处理器去并行解决同一个问题，使得性能与规模增大。

- 实现方式：结构比较紧密，各节点之间通过高速网络连接，如超级计算机。
- 实时性:要求每个节点的结算结果要绝对正确，在时间上做到同步

分布式计算:
- 一个程序与其他程序协作来解决某个问题，通常是把非常巨大的计算能力才可以解决的问题分解为许多小部分，交给不同的计算机来进行处理，最后把这些结果综合起来得到结果
- 目的：资源共享与应用，然后直接在系统上互相沟通传递资料
- 实现方式：结构松散，节点之间几乎不相互通信
- 实时性：分布式的计算被分解后，每个小任务相互独立，节点间的结果不互相影响，实时性要求不高
## 警告
仅凭感觉来编写并行程序很诱人，但是并不可靠

# 并行硬件与并行软件
## 冯.诺依曼结构
![](D:/VSCode\blog_picture\冯诺依曼.png)

经典结构包括:
==主存、中央处理单元(Central Processing Unit,CPU)或核、主存与CPU的互连结构==
- 主存中的每个区域都可以存储指令与数据
- ==中央处理单元分为控制单元和算术逻辑单元==(Arithmetic Logic Unit,ALU),==控制单元负责决定执行程序中的哪些指令==，==算术逻辑单元负责执行指令==。

CPU中的数据和程序执行时的状态信息存储在特殊的快速存储介质中，即==寄存器==。

控制单元中有一个特殊的寄存器称为==程序计数器==(PC)，用来存放下一条指令的地址。

指令和数据通过CPU和主存间的互连结构进行传输，称为==总线==，总线中==包括一组并行的线以及控制这些线的硬件==。
冯诺依曼机器一次执行一条指令，每条指令对一个数据进行操作。

当数据或指令从主存传送到CPU时，我们称为数据或指令从内存中==取出==或者==读出==。

而当数据或指令从CPU传送到主存中时，我们称数据或指令==写入或者存入内存==中。

主存与CPU之间的分离称为==冯.诺依曼瓶颈==，这是由于==互连结构限制了指令与数据访问的速率==。相当于读出写入的速率大于运输速率。

为了解决冯诺依曼瓶颈，科学家们进行了修改。


## 对冯.诺依曼模型的改进
## Cache
高速缓冲存储器(cache,缓存)的访问时间比其他存储区域的访问时间短，在本书中，谈到缓存一般指CPU缓存，它是一组相比于主存，CPU可以更快地访问到的存储区域。

冯诺依曼结构改进后，不再将所有的数据与指令存储在主存中，可以将部分数据块或者代码块存储在缓存中。

但是什么样的数据与指令可以存储在cache中呢？

通用的准则是:
程序接下来可能会用到的指令和数据与最近访问过的指令和数据在物理上是邻近存放的，在执行完一条指令后，程序通常会执行下一条指令。

程序访问完一个存储区域往往会访问接下来的区域，这个原理称为局部性原理。

- 时间局部性：程序在不久的将来进行访问。

- 空间局部性：访问临近的区域。

为了运用局部性原理，系统使用更宽的互连结构来访问数据与指令，也就是:==一次内存访问能存取一整块代码和数据，而非单条指令与数据==。

这些块称为高速缓存块或者高速缓存行，

CPU cache分为不同的层，第一层最小但最快，越往上越大也越慢。

Cache通常用来存储速度较慢的存储器中信息的副本，可以认为底层Cache是高层Cache的Cache。所以，一个变量存储在L1中，也会存储在L2中，但是有些多层Cache不会复制已经存在其它层中存在的信息。对这种Cache，L1中存储的不会存在其他层，但会存在主存中。

查询数据时，沿着Cache的层次结构向下查询，首先查询L1、接着L2，以此类推。

如果Cache中没有才会访问主存。

如果Cache中有信息，称为==Cache命中，或命中==。

如果信息不存在Cache中，则==称为Cache缺失或者缺失。==

存储器的访问术语读与写也适用于Cache。

当CPU尝试访问指令或者数据时，如果发生Cache缺失，就会从主存中读取，此时CPU就会阻塞，需要等待相对较慢的主存。

当CPU向Cache写数据时，Cache中的值与主存中的值就可能会变得不一致。

有两种方法解决:
- 写直达Cache中：当CPU向Cache写入数据时，Cache会立即向主存中写入
- 写回Cache中：数据不是立即更新到主存中，而是将高速缓存行标记为脏，发生高速缓存行替换时，标记为脏的高速缓存行被写入主存中。


## 进程、多任务与线程
==操作系统==(Operating System，OS)是用来管理计算机的软件与硬件资源的主要软件。

作用
- 用来管理计算机的软件与硬件资源的主要软件
- 决定什么程序能运行及什么时候运行
- 控制运行中程序的内存分配以及硬盘、网盘等外设的访问

当用户==运行一个程序时，操作系统创建一个进程==，==进程是运行着的程序的一个实例==，一个进程包含以下实体:
- ==可执行的机器语言程序==
- ==一块内存空间==，包括可执行代码、一个用来跟踪执行函数的调用栈、一个堆、以及一些其他内存区域
- 操作系统分配给进程的==资源描述符==
- ==安全信息==
- ==进程状态信息==

==大多数线代操作系统都是多任务的==，这意味着操作系统提供对同时运行多个程序的支持，这对于==单核系统也是可行的==，因为每个进程只运行一小段时间(几毫秒),也即为一个==时间片==，==在操作系统执行了一个时间片的时间后，操作系统就切换执行其他程序==，一个多任务系统能够在一分钟内多次切换运行的程序。

多进程/多任务
- 给出一个单处理器同时运行多个程序的错觉
- 每个进程轮流进行(时间片:几毫秒)
- 在一个进行的时间片结束后，它将等待直到再次轮到它进行
![](D:/VSCode\blog_picture\时间片.png)


当一个多任务操作系统，如果一个进程等待某个资源，它会==阻塞==。

线程为程序员提供了一种机制，将程序划分为多个大致独立的任务，但某个任务阻塞时能够执行其他的任务。

线程的切换比进程的切换要快。

线程包含在进程中，多个线程可以共享内存与I/O设备。但它们可以独立运行。

当一个线程开始时，它从进程中派生(fork)出来，当一个线程结束，它合并到进程中。

![](D:/VSCode\blog_picture\线程与进程.png)

并行硬件
计算机一次运行一个程序

并行计算机分类:
Flynn分类法经常用来对计算机体系结构进行分类
- 1966年被提出
- 从处理器的角度进行分类：按照处理器能够同时管理的指令流数目和数据流数目来对系统分类
    - SISD
      - 单指令数据流(SISD)是一个串行的计算机系统
      - 单指令:在一个时钟周期内只有一个指令流被CPU进行处理
      - 单数据:在一个时钟周期内只有一个数据流作为输入而使用A
        ![](D:/VSCode\blog_picture\SISD.png)

    - SIMD
      - 并行系统
      - 单指令：在一个时钟周期内，所有处理器单元执行相同的指令
      - 多数据流:每个处理器单元能够作用在不同的数据单元上
      - 通过对多个数据执行相同的指令从而实现在多个数据流上的操作         ![](D:/VSCode\blog_picture\SIMD.png)
      - 一个抽象的SIMD=一个控制单元+多个ALU  
      - [](D:/VSCode\blog_picture\SIMDeg.png
    - MISD
    - MIMD
![](D:/VSCode\blog_picture\Flynn.png)


## 虚拟存储器

## 低层次并行



第三章作业
3.6
3.8

